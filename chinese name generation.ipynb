{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I342070\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as ks\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, SimpleRNN, Activation, LSTM, Reshape, Lambda, Dense\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique characters: len = 3757\n"
     ]
    }
   ],
   "source": [
    "filepath = 'data/chi_names.txt'\n",
    "data = open(filepath, encoding='utf-8').read().lower()\n",
    "uniq = set(data)\n",
    "ndim = len(uniq)\n",
    "print('unique characters: len =', ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2arr(name):\n",
    "    arr = np.zeros((len(name), ndim))\n",
    "    for i, ch in enumerate(name):\n",
    "        arr[i, ch2idx[ch]] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def arr2word(arr, showProb=False):\n",
    "    name = ''\n",
    "    prob = 1.0\n",
    "    for vec in arr:\n",
    "        ch = np.random.choice(ndim, p=vec)\n",
    "        if showProb:\n",
    "            print(vec[ch])\n",
    "        prob *= vec[ch]\n",
    "        name += idx2ch[ch]\n",
    "    return name, prob\n",
    "\n",
    "import pickle\n",
    "def save_dict(filepath, dict_obj):\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(dict_obj, f)\n",
    "\n",
    "        \n",
    "def load_dict(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2idx = {word: idx for idx, word in enumerate(uniq)}\n",
    "idx2ch = {idx: word for idx, word in enumerate(uniq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, None, 3757)        0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 128)         497408    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 3757)        484653    \n",
      "=================================================================\n",
      "Total params: 982,061\n",
      "Trainable params: 982,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden = 128\n",
    "rnn_cell = SimpleRNN(hidden, return_sequences=True)\n",
    "\n",
    "x = Input(shape=(None, ndim), name='x')\n",
    "out = rnn_cell(x)\n",
    "out = Dense(ndim, activation='softmax')(out)\n",
    "\n",
    "model = Model(x, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: traning model using variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (86716 of 86716) |###################| Elapsed Time: 0:13:37 ETA:  0:00:00"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from random import shuffle\n",
    "import progressbar\n",
    "lines = open(filepath, encoding='utf-8').readlines()\n",
    "shuffle(lines)\n",
    "\n",
    "counter = 0\n",
    "bar = progressbar.ProgressBar(max_value=len(lines))\n",
    "for length, chunks in groupby(lines, key=len):\n",
    "    chk = list(chunks)\n",
    "    arr = np.zeros((len(chk), length, ndim), dtype=bool)\n",
    "    counter += len(chk)\n",
    "    for i, name in enumerate(chk):\n",
    "        for j, ch in enumerate(name):\n",
    "            arr[i, j, ch2idx[ch]] = 1\n",
    "    x = arr[:, :-1]\n",
    "    y = arr[:, 1:]\n",
    "    model.fit(x, y, batch_size=128, verbose=0)\n",
    "    bar.update(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: padding name to maxlength using '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_name(name, max_length):\n",
    "    name += '\\n' * (max_length - len(name))\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "lines = open(filepath, encoding='utf-8').readlines()\n",
    "shuffle(lines)\n",
    "max_length = len(max(lines, key=len))\n",
    "lines = [padding_name(name, max_length) for name in lines]\n",
    "\n",
    "def batch_generator(lines, batch_size=128):\n",
    "    chunks = [lines[i:i + batch_size] for i in range(0, len(lines), batch_size)]\n",
    "    while True:\n",
    "        for chunk in chunks:\n",
    "            arr = np.zeros((batch_size, max_length, ndim))\n",
    "            for i, name in enumerate(chunk):\n",
    "                for j, ch in enumerate(name):\n",
    "                    arr[i, j, ch2idx[ch]] = 1\n",
    "            x = arr[:, :-1]\n",
    "            y = arr[:, 1:]\n",
    "            yield (x, y)\n",
    "\n",
    "model.fit_generator(generator=batch_generator(lines), steps_per_epoch=len(lines)/128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Since Python use different random seed for hash function in every session, in order to reload trained model, you cannot save only model itself, but also ch2idx, idx2ch object as well because these 2 objects use set function to generate dict object.\n",
    "\n",
    "See also https://stackoverflow.com/a/27522708/7620214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model/chi_name.h5')\n",
    "\n",
    "# save dict\n",
    "save_dict('model/ch2idx.pkl', ch2idx)\n",
    "save_dict('model/idx2ch.pkl', idx2ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('model/chi_name.h5')\n",
    "\n",
    "# load dict\n",
    "ch2idx = load_dict('model/ch2idx.pkl')\n",
    "idx2ch = load_dict('model/idx2ch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(first_name):\n",
    "    name = first_name\n",
    "    last_prob = 1\n",
    "    for i in range(1, 10):\n",
    "        next = word2arr(name)\n",
    "        next = model.predict(next.reshape(1, i, ndim))\n",
    "        ch, prob = arr2word(next.reshape(i, ndim)[-1].reshape(1, ndim))\n",
    "        if ch[0] is '\\n':\n",
    "            break\n",
    "        name += ch[0]\n",
    "        last_prob = prob\n",
    "    return name, last_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('陈天雄', 0.003409971483051777)\n",
      "('陈澍', 3.940694296034053e-05)\n",
      "('陈', 1)\n",
      "('陈海厚', 0.0002645377826411277)\n",
      "('陈概张', 0.00016857880109455436)\n",
      "('陈清', 0.0034715617075562477)\n",
      "('陈灵尤', 0.0003563206410035491)\n",
      "('陈桃', 0.0003612065629567951)\n",
      "('陈博', 0.001150886993855238)\n",
      "('陈秀海', 0.008844899013638496)\n",
      "('张东', 0.005207078997045755)\n",
      "('张怀伯', 0.0002961941354442388)\n",
      "('张凤学', 0.0027856621891260147)\n",
      "('张赞双', 0.0009214482852257788)\n",
      "('张华', 0.010215764865279198)\n",
      "('张璇', 0.00032445212127640843)\n",
      "('张静锋', 0.004459536634385586)\n",
      "('张亚', 0.003247500630095601)\n",
      "('张双', 0.0015154107240960002)\n",
      "('张立树', 0.002470780862495303)\n",
      "('王美', 0.004075216129422188)\n",
      "('王强', 0.0023727361112833023)\n",
      "('王维', 0.003937355242669582)\n",
      "('王', 1)\n",
      "('王家海', 0.00729594798758626)\n",
      "('王仙雯', 0.001730739139020443)\n",
      "('王小青', 0.002841019770130515)\n",
      "('王铁成', 0.0037237636279314756)\n",
      "('王雪革', 0.00010903873044298962)\n",
      "('王晗', 0.0004707835614681244)\n",
      "('赵阳月', 0.0014148115878924727)\n",
      "('赵苏', 0.0009791180491447449)\n",
      "('赵承', 0.0010355053236708045)\n",
      "('赵儿', 0.00010591329191811383)\n",
      "('赵惠顺', 0.0009885582840070128)\n",
      "('赵俊龙', 0.003401790978386998)\n",
      "('赵名送', 5.0774997362168506e-05)\n",
      "('赵春', 0.006388045847415924)\n",
      "('赵杰暗单', 1.127494101638149e-06)\n",
      "('赵錋怀', 0.0007263431907631457)\n",
      "('钱金雪', 0.005266516003757715)\n",
      "('钱轩', 0.0008799805655144155)\n",
      "('钱匀律', 1.6523901649634354e-05)\n",
      "('钱萍', 0.0024958450812846422)\n",
      "('钱树国', 0.009831716306507587)\n",
      "('钱顺蓉', 0.0003970460093114525)\n",
      "('钱', 1)\n",
      "('钱丽林', 0.007723722606897354)\n",
      "('钱', 1)\n",
      "('钱锡', 0.000505014497321099)\n",
      "('孙福兰', 0.004120360128581524)\n",
      "('孙士龙', 0.006257377099245787)\n",
      "('孙小峰', 0.012821918353438377)\n",
      "('孙朋珈', 1.3993028915137984e-05)\n",
      "('孙红建冬', 0.00016280119598377496)\n",
      "('孙宾', 0.0004802801413461566)\n",
      "('孙浦绍', 0.000513463921379298)\n",
      "('孙辉', 0.0027299891225993633)\n",
      "('孙高凤', 0.005233148578554392)\n",
      "('孙桃', 0.00036969242501072586)\n",
      "('李彦君', 0.010209905914962292)\n",
      "('李至', 5.951545972493477e-05)\n",
      "('李炳钢', 0.0006808295729570091)\n",
      "('李秀洁', 0.003476619254797697)\n",
      "('李', 1)\n",
      "('李发', 0.001941175665706396)\n",
      "('李豪', 0.0005417902721092105)\n",
      "('李廷峰', 0.005865912884473801)\n",
      "('李敏学', 0.002142641693353653)\n",
      "('李雪林', 0.00778083223849535)\n",
      "('黄', 1)\n",
      "('黄鑫万', 0.0005554435192607343)\n",
      "('黄栩', 7.048586121527478e-05)\n",
      "('黄俊', 0.0035705072805285454)\n",
      "('黄金', 0.012389522045850754)\n",
      "('黄高科', 0.0005833536270074546)\n",
      "('黄懿金', 0.001584418467245996)\n",
      "('黄善强', 0.007138608023524284)\n",
      "('黄冬秋', 0.003073829459026456)\n",
      "('黄贯', 3.071443643420935e-05)\n",
      "('周天森', 0.0007354000699706376)\n",
      "('周冬芸', 0.00022527806868311018)\n",
      "('周贺强', 0.007878817617893219)\n",
      "('周钢渭', 4.466229074751027e-05)\n",
      "('周文君', 0.012438934296369553)\n",
      "('周', 1)\n",
      "('周开志', 0.0035901686642318964)\n",
      "('周海', 0.012229272164404392)\n",
      "('周艰', 1.619641625438817e-05)\n",
      "('周军塑', 8.454629096377175e-06)\n",
      "('杨金龄', 6.789417238906026e-05)\n",
      "('杨勇荣', 0.0032913656905293465)\n",
      "('杨洋', 0.0006798285758122802)\n",
      "('杨欣', 0.0014612673548981547)\n",
      "('杨炳军', 0.009760626591742039)\n",
      "('杨敏杰', 0.0053070541471242905)\n",
      "('杨乙长金学', 0.00018956030544359237)\n",
      "('杨少裕', 0.00022915698355063796)\n",
      "('杨学建', 0.0048697758466005325)\n",
      "('杨蓉', 0.0006176361930556595)\n",
      "('何玉素', 0.000663476181216538)\n",
      "('何清', 0.004237792920321226)\n",
      "('何亚梅', 0.006183322984725237)\n",
      "('何中喜', 0.0020629295613616705)\n",
      "('何秀', 0.0071183363907039165)\n",
      "('何少珺', 6.0497648519231007e-05)\n",
      "('何泰', 0.00011066946171922609)\n",
      "('何', 1)\n",
      "('何杨鑫', 0.0012654404854401946)\n",
      "('何林兴', 0.00361726270057261)\n",
      "('欧琼', 0.0005454557249322534)\n",
      "('欧', 1)\n",
      "('欧向哲士', 0.0003164131776429713)\n",
      "('欧全', 0.0022280400153249502)\n",
      "('欧方', 0.0022452641278505325)\n",
      "('欧烬松', 0.0008224410121329129)\n",
      "('欧飞', 0.003097016829997301)\n",
      "('欧松凯', 0.001153696677647531)\n",
      "('欧华卯', 1.0633722922648303e-05)\n",
      "('欧桃', 0.0003568786778487265)\n",
      "('上晓', 0.004501132294535637)\n",
      "('上少岗', 0.0001555448106955737)\n",
      "('上良', 0.001489261630922556)\n",
      "('上治', 0.0004676227399613708)\n",
      "('上', 1)\n",
      "('上一海', 0.003646448953077197)\n",
      "('上晓', 0.004501132294535637)\n",
      "('上', 1)\n",
      "('上', 1)\n",
      "('上', 1)\n"
     ]
    }
   ],
   "source": [
    "first_name = ['陈', '张', '王', '赵', '钱', '孙', '李', '黄', '周', '杨', '何', '欧', '上']\n",
    "for name in first_name:\n",
    "    for _ in range(10):\n",
    "        print(sample(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
